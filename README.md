# Welcome to my new data ingestion project!

This project is part of the Stack Academy Zero Data Engineering course. Our goal is to create a complex process bath and real-time data ingestion with Python API, Aws RDS / S3 and Airbyte.

Let's develop a simple data pipeline involving Python, API and Json files. The data will be queried and extracted through a public API in Json format, transformed and analyzed in Python and persisted in an AWS relational database. After this process, we will evolve to a more professional solution.

![image](https://user-images.githubusercontent.com/44467803/185740510-15b90bf7-488c-4816-9133-0efab3d5a3be.png)


# Fonte de Dados

Portal CoinMarketCap: https://coinmarketcap.com/ <br />
Get your API: https://coinmarketcap.com/api/documentation/v1/#section/Quick-Start-Guide

![image](https://user-images.githubusercontent.com/44467803/185741192-c0194ab1-d70c-4dff-b5ad-11823841b55a.png)

# Development

 - know the data available for collection via API
 - get the key and understand the CoinMarketCap API documentation
 - understand Python code and data collection
 - view get() method response for data extraction
 - understand the logic to get the data from the API
 - validate API return data
 - persist data in RDS database on AWS
 - knowing the SQLAlchemy library
 - create RDS database instances on AWS
 - adjust permissions in security group for bank access
 - configure Python application features and parameters
 - run Python application for data collection
 - know the features of the Open Source Airbyte tool
 - create sources and destinations in Airbyte pointing to RDS instance and Bucket S3 in AWS
 - run extract on Airbyte and validate results on AWS
 - understand Chage Data Capture requirements on Airbyte with Postgres SQL(RDS) on AWS
 - create parameter group on AWS instance
 - create "publication" and "logical_replication_slot" in Postgres SQL
 - create "destinations" and "configuration" in Airbyte to run in CDC mode
 - change data in Postegres SQL database and run sync on Airbyte in CDC
 - validate writing of new data to AWS S3 bucket

![image](https://user-images.githubusercontent.com/44467803/185739014-cc202486-e330-4648-a563-40d390dd445f.png)


![image](https://user-images.githubusercontent.com/44467803/185739141-9440f104-04d0-4da0-a7d9-dfe65ed60be5.png)


![image](https://user-images.githubusercontent.com/44467803/185739361-3cbad4e7-8562-45e4-8880-8cf900736236.png)


![image](https://user-images.githubusercontent.com/44467803/185739773-ddb5ad87-5e2c-4154-a7c8-01623207e8ff.png)
